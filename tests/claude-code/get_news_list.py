import json
import os
import requests
import urllib3
from datetime import datetime, timedelta
import sys

urllib3.disable_warnings()

def get_news_list(topic, news_ids_str, topic_folder_path):
    """íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ë‰´ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    url = "https://bigkinds.or.kr/news/getNetworkDataAnalysis.do"
    
    headers = {
        "Referer": "https://www.bigkinds.or.kr/",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "X-Requested-With": "XMLHttpRequest"
    }
    
    # ë‚ ì§œ ì„¤ì • (ì–´ì œë¶€í„° ì˜¤ëŠ˜ê¹Œì§€)
    today = datetime.now()
    start_date = (today - timedelta(days=1)).strftime("%Y-%m-%d")
    end_date = today.strftime("%Y-%m-%d")
    
    data = {
        "pageInfo": "newsResult",
        "keyword": topic,
        "startDate": start_date,
        "endDate": end_date,
        "newsCluster": news_ids_str,
        "resultNo": "100",
    }
    
    response = requests.post(url, headers=headers, data=data, verify=False)
    response.raise_for_status()
    
    # ì‘ë‹µ ë°ì´í„° ì €ì¥
    response_data = response.json()
    
    
    return response_data

def extract_news_data(response_data, topic):
    """ì‘ë‹µ ë°ì´í„°ì—ì„œ ë‰´ìŠ¤ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    extracted_data = {
        "topic": topic,
        "extraction_timestamp": datetime.now().isoformat(),
        "total_news": 0,
        "news_list": []
    }
    
    if "newsList" in response_data:
        news_list = response_data["newsList"]
        extracted_data["total_news"] = len(news_list)
        
        for news_item in news_list:
            news_data = {
                "news_id": news_item.get("news_node_id", ""),
                "title": news_item.get("title", ""),
                "provider_name": news_item.get("provider_name", ""),
                "byline": news_item.get("byline", ""),
                "published_date": news_item.get("published_date", ""),
                "summary": news_item.get("summary", ""),
                "keywords": [kw.get("label", "") for kw in news_item.get("inKeyword", [])],
                "category": news_item.get("category", ""),
                "url": news_item.get("url", "")
            }
            extracted_data["news_list"].append(news_data)
    
    # newsIdsê°€ ìˆë‹¤ë©´ ì¶”ê°€
    if "newsIds" in response_data:
        extracted_data["news_ids"] = response_data["newsIds"]
    
    return extracted_data

def load_topic_data(folder_path):
    """ê¸°ì¡´ì— ì¶”ì¶œëœ ì£¼ì œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    json_path = os.path.join(folder_path, "topic-list.json")
    
    if not os.path.exists(json_path):
        print(f"ì£¼ì œ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path}")
        return None
    
    with open(json_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_news_data(news_data, topic_folder_path):
    """ë‰´ìŠ¤ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    json_path = os.path.join(topic_folder_path, "news-list.json")
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(news_data, f, ensure_ascii=False, indent=2)
    
    return json_path

def main():
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python get_news_list.py <bigkinds_folder_path> [topic_rank]")
        print("ì˜ˆì‹œ: python get_news_list.py bigkinds-2025-06-20T22:00:54.999029")
        print("ì˜ˆì‹œ: python get_news_list.py bigkinds-2025-06-20T22:00:54.999029 1")
        return
    
    folder_path = sys.argv[1]
    specific_rank = int(sys.argv[2]) if len(sys.argv) > 2 else None
    
    if not os.path.exists(folder_path):
        print(f"í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
        return
    
    # ì£¼ì œ ë°ì´í„° ë¡œë“œ
    topic_data = load_topic_data(folder_path)
    if not topic_data:
        return
    
    topics = topic_data["topics"]
    
    # íŠ¹ì • ìˆœìœ„ë§Œ ì²˜ë¦¬í•˜ê±°ë‚˜ ëª¨ë“  ì£¼ì œ ì²˜ë¦¬
    topics_to_process = []
    if specific_rank:
        topic_found = None
        for topic in topics:
            if topic["rank"] == specific_rank:
                topic_found = topic
                break
        if topic_found:
            topics_to_process = [topic_found]
        else:
            print(f"ìˆœìœ„ {specific_rank}ì— í•´ë‹¹í•˜ëŠ” ì£¼ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    else:
        topics_to_process = topics[:3]  # ìƒìœ„ 3ê°œë§Œ ì²˜ë¦¬
    
    import time
    total_start_time = time.time()
    
    print(f"ì´ {len(topics_to_process)}ê°œ ì£¼ì œì˜ ë‰´ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤...")
    
    for topic_info in topics_to_process:
        topic_start_time = time.time()
        rank = topic_info["rank"]
        topic = topic_info["topic"]
        news_ids_str = ",".join(topic_info["news_ids"])
        
        print(f"\n[{rank}] {topic}")
        print(f"ë‰´ìŠ¤ ID ê°œìˆ˜: {len(topic_info['news_ids'])}ê°œ")
        
        try:
            # ì£¼ì œë³„ í´ë” ìƒì„±
            folder_creation_start = time.time()
            topic_folder_path = os.path.join(folder_path, f"topic-{rank:02d}")
            os.makedirs(topic_folder_path, exist_ok=True)
            folder_creation_time = time.time() - folder_creation_start
            
            # ë‰´ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            api_start = time.time()
            response_data = get_news_list(topic, news_ids_str, topic_folder_path)
            api_time = time.time() - api_start
            
            # ë°ì´í„° ì¶”ì¶œ
            extraction_start = time.time()
            news_data = extract_news_data(response_data, topic)
            extraction_time = time.time() - extraction_start
            
            # JSONìœ¼ë¡œ ì €ì¥
            save_start = time.time()
            json_path = save_news_data(news_data, topic_folder_path)
            save_time = time.time() - save_start
            
            topic_total_time = time.time() - topic_start_time
            
            print(f"âœ… ë‰´ìŠ¤ {news_data['total_news']}ê°œë¥¼ {topic_folder_path}/ í´ë”ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            print(f"   ğŸ“ {topic_folder_path}/news-list.json")
            print(f"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {topic_total_time:.3f}ì´ˆ (API: {api_time:.3f}ì´ˆ, ì¶”ì¶œ: {extraction_time:.3f}ì´ˆ, ì €ì¥: {save_time:.3f}ì´ˆ)")
            
            # ì²˜ìŒ ëª‡ ê°œ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°
            for i, news in enumerate(news_data["news_list"][:3]):
                print(f"   {i+1}. {news['title'][:50]}...")
                print(f"      ğŸ“° {news['provider_name']} | {news['byline']}")
        
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    total_time = time.time() - total_start_time
    print(f"\nâ±ï¸  ì „ì²´ ë‰´ìŠ¤ ëª©ë¡ ì¶”ì¶œ ì™„ë£Œ ì‹œê°„: {total_time:.3f}ì´ˆ")

if __name__ == "__main__":
    main()