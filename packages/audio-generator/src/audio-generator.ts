import { promises as fs } from 'fs';
import path from 'path';

import {
  NewscastScript,
  AudioGenerationResult,
  AudioGeneratorConfig,
  AudioGeneratorConfigSchema,
  DialogueLine,
  AudioFileInfo,
} from './types/index.js';
import { TTSService } from './services/tts-service.js';
import { VoiceMappingService } from './services/voice-mapping.js';
import { AudioProgressTracker, ProgressCallback } from './monitoring/progress-tracker.js';
import { ErrorHandler, AudioGenerationError } from './utils/error-handler.js';

/**
 * Main audio generator class that orchestrates TTS generation
 */
export class AudioGenerator {
  private readonly ttsService: TTSService;
  private readonly config: AudioGeneratorConfig;

  constructor(config: Partial<AudioGeneratorConfig> = {}) {
    // Validate and set default configuration
    this.config = AudioGeneratorConfigSchema.parse(config);
    this.ttsService = new TTSService(this.config);
  }

  /**
   * Generate audio files for a newscast script
   */
  public async generateNewscastAudio(
    scriptPath: string,
    outputDirectory: string,
    progressCallback?: ProgressCallback
  ): Promise<AudioGenerationResult> {
    console.log('ğŸ™ï¸ ë‰´ìŠ¤ìºìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„± ì‹œì‘...');
    const totalStartTime = performance.now();

    try {
      // Load and validate script
      const script = await this.loadScript(scriptPath);
      
      // Setup output directory
      const audioFolderPath = path.join(outputDirectory, this.config.outputConfig.audioFolder);
      await fs.mkdir(audioFolderPath, { recursive: true });

      // Initialize progress tracking
      const dialogueCount = script.dialogue_lines.filter(line => line.type === 'dialogue').length;
      const musicCount = script.dialogue_lines.filter(line => line.type !== 'dialogue').length;
      const progressTracker = new AudioProgressTracker(dialogueCount, musicCount, progressCallback);

      console.log(`   ğŸ“Š ì´ ëŒ€ì‚¬ ë¼ì¸: ${script.dialogue_lines.length}ê°œ`);
      console.log(`   ğŸ‘¥ ì§„í–‰ì: ${script.hosts.host1.name} (${script.hosts.host1.voice_model}), ${script.hosts.host2.name} (${script.hosts.host2.voice_model})`);
      console.log(`   ğŸ’¬ ëŒ€í™” êµ¬ê°„: ${dialogueCount}ê°œ, ìŒì•… êµ¬ê°„: ${musicCount}ê°œ`);

      // Validate TTS service
      if (!(await this.ttsService.validateCredentials())) {
        console.warn('âš ï¸ Google Cloud TTS ì¸ì¦ ê²€ì¦ ì‹¤íŒ¨. ê³„ì† ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤...');
      }

      // Generate audio for each dialogue line (ë³‘ë ¬ ì²˜ë¦¬)
      console.log('\\nğŸµ ê°œë³„ ëŒ€ì‚¬ ë¼ì¸ ì˜¤ë””ì˜¤ ìƒì„± ì¤‘... (ë³‘ë ¬ ì²˜ë¦¬)');
      const audioGenerationStart = performance.now();
      
      const audioFiles: AudioFileInfo[] = [];

      // ëŒ€í™” ë¼ì¸ë§Œ í•„í„°ë§ (ìŒì•… êµ¬ê°„ì€ ìŠ¤í‚µ)
      const dialogueLines = script.dialogue_lines.filter(line => line.type === 'dialogue');
      const musicLines = script.dialogue_lines.filter(line => line.type !== 'dialogue');
      
      // ìŒì•… êµ¬ê°„ ìŠ¤í‚µ ì²˜ë¦¬
      musicLines.forEach(() => progressTracker.recordSkip());
      
      if (dialogueLines.length === 0) {
        console.log('   â„¹ï¸ ì²˜ë¦¬í•  ëŒ€í™” ë¼ì¸ì´ ì—†ìŠµë‹ˆë‹¤.');
      } else {
        // ë³‘ë ¬ ì²˜ë¦¬ (ë™ì‹œ ìµœëŒ€ 3ê°œ, Rate Limiting ê³ ë ¤)
        const maxConcurrency = 3;
        const results = await this.processDialoguesInBatches(
          dialogueLines, 
          audioFolderPath, 
          outputDirectory, 
          maxConcurrency, 
          progressTracker
        );
        
        audioFiles.push(...results);
      }

      const audioGenerationTime = performance.now() - audioGenerationStart;

      // Generate result metadata
      const result = await this.generateResult(
        script,
        audioFiles,
        progressTracker,
        audioGenerationTime,
        outputDirectory
      );

      // Save result metadata
      await this.saveResultMetadata(result, audioFolderPath);

      const totalTime = performance.now() - totalStartTime;
      
      // Print completion summary
      this.printCompletionSummary(result, audioFolderPath, totalTime);

      return result;

    } catch (error) {
      const audioError = ErrorHandler.handleTTSError(error, 'ì˜¤ë””ì˜¤ ìƒì„±');
      console.error(`\\nâŒ ${ErrorHandler.getUserFriendlyMessage(audioError)}`);
      throw audioError;
    }
  }

  /**
   * ëŒ€í™” ë¼ì¸ë“¤ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ë³‘ë ¬ ì²˜ë¦¬
   */
  private async processDialoguesInBatches(
    dialogueLines: DialogueLine[],
    audioFolderPath: string,
    outputDirectory: string,
    maxConcurrency: number,
    progressTracker: AudioProgressTracker
  ): Promise<AudioFileInfo[]> {
    const audioFiles: AudioFileInfo[] = [];
    
    console.log(`   ğŸ“Š ì´ ${dialogueLines.length}ê°œ ëŒ€í™” ë¼ì¸ì„ ${maxConcurrency}ê°œì”© ë³‘ë ¬ ì²˜ë¦¬`);
    
    for (let i = 0; i < dialogueLines.length; i += maxConcurrency) {
      const batch = dialogueLines.slice(i, i + maxConcurrency);
      const batchNumber = Math.floor(i / maxConcurrency) + 1;
      const totalBatches = Math.ceil(dialogueLines.length / maxConcurrency);
      
      console.log(`   ğŸ”„ ë°°ì¹˜ ${batchNumber}/${totalBatches} ì²˜ë¦¬ ì¤‘... (${batch.length}ê°œ ë¼ì¸)`);
      
      // ë°°ì¹˜ ë‚´ ëª¨ë“  ëŒ€í™” ë¼ì¸ì„ ë³‘ë ¬ ì²˜ë¦¬
      const batchPromises = batch.map(async (dialogue) => {
        return await this.processSingleDialogue(
          dialogue, 
          audioFolderPath, 
          outputDirectory, 
          progressTracker
        );
      });
      
      // ë°°ì¹˜ ì™„ë£Œ ëŒ€ê¸°
      const batchResults = await Promise.allSettled(batchPromises);
      
      // ì„±ê³µí•œ ê²°ê³¼ë§Œ ìˆ˜ì§‘
      batchResults.forEach((result, index) => {
        if (result.status === 'fulfilled' && result.value) {
          audioFiles.push(result.value);
        } else if (result.status === 'rejected') {
          const dialogue = batch[index];
          console.error(`   âŒ ëŒ€ì‚¬ ë¼ì¸ ${dialogue.sequence} ì²˜ë¦¬ ì‹¤íŒ¨:`, result.reason);
        }
      });
      
      console.log(`   âœ… ë°°ì¹˜ ${batchNumber} ì™„ë£Œ`);
      
      // Rate limiting: ë°°ì¹˜ ê°„ ì§§ì€ ì§€ì—°
      if (i + maxConcurrency < dialogueLines.length) {
        await new Promise(resolve => setTimeout(resolve, 500));
      }
    }
    
    return audioFiles.sort((a, b) => a.sequence - b.sequence);
  }

  /**
   * ê°œë³„ ëŒ€í™” ë¼ì¸ ì²˜ë¦¬
   */
  private async processSingleDialogue(
    dialogue: DialogueLine,
    audioFolderPath: string,
    outputDirectory: string,
    progressTracker: AudioProgressTracker
  ): Promise<AudioFileInfo | null> {
    const startTime = performance.now();
    
    try {
      const audioFileName = this.ttsService.generateAudioFilename(dialogue);
      const audioFilePath = path.join(audioFolderPath, audioFileName);
      
      await this.ttsService.generateAudio(dialogue, audioFilePath);
      
      const audioFileInfo: AudioFileInfo = {
        file_path: path.relative(outputDirectory, audioFilePath),
        sequence: dialogue.sequence,
        type: dialogue.type,
        speaker: VoiceMappingService.getDisplayName(dialogue.speaker),
      };
      
      const processingTime = performance.now() - startTime;
      progressTracker.recordSuccess(processingTime);
      
      return audioFileInfo;
      
    } catch (error) {
      const audioError = ErrorHandler.handleTTSError(error, `ëŒ€ì‚¬ ë¼ì¸ ${dialogue.sequence}`);
      console.error(`   âŒ ${ErrorHandler.getUserFriendlyMessage(audioError)}`);
      progressTracker.recordFailure(audioError);
      
      if (!audioError.retryable) {
        console.warn(`   âš ï¸ ëŒ€ì‚¬ ë¼ì¸ ${dialogue.sequence}: ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜ë¡œ ê±´ë„ˆëœ€`);
      }
      
      return null;
    }
  }

  /**
   * Load and validate newscast script
   */
  private async loadScript(scriptPath: string): Promise<NewscastScript> {
    console.log('ğŸ“„ ë‰´ìŠ¤ìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ë¡œë”© ì¤‘...');
    const loadStartTime = performance.now();
    
    try {
      const scriptContent = await fs.readFile(scriptPath, 'utf-8');
      const script = JSON.parse(scriptContent) as NewscastScript;
      
      const loadTime = performance.now() - loadStartTime;
      console.log(`   â±ï¸ ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ: ${loadTime.toFixed(1)}ms`);
      
      return script;
    } catch (error) {
      if (error && typeof error === 'object' && 'code' in error && error.code === 'ENOENT') {
        throw new AudioGenerationError(
          `ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${scriptPath}`,
          'SCRIPT_NOT_FOUND',
          false,
          { scriptPath }
        );
      }
      throw ErrorHandler.handleTTSError(error, 'ìŠ¤í¬ë¦½íŠ¸ ë¡œë”©');
    }
  }

  /**
   * Generate final result object
   */
  private async generateResult(
    script: NewscastScript,
    audioFiles: AudioFileInfo[],
    progressTracker: AudioProgressTracker,
    audioGenerationTime: number,
    outputDirectory: string
  ): Promise<AudioGenerationResult> {
    const stats = progressTracker.getStats();
    
    return {
      title: script.title,
      program_name: script.program_name,
      generation_timestamp: new Date().toISOString(),
      total_dialogue_lines: script.dialogue_lines.length,
      dialogue_lines: stats.totalDialogueLines,
      music_lines: stats.musicLines,
      generated_audio_files: stats.successCount,
      skipped_music_files: stats.skipCount,
      failed_audio_files: stats.failCount,
      audio_files: audioFiles,
      all_segments: script.dialogue_lines.map(line => ({
        ...line,
        has_audio: line.type === 'dialogue' && audioFiles.some(f => f.sequence === line.sequence),
      })),
      metadata: {
        audio_generation_time_ms: audioGenerationTime,
        success_rate: `${stats.totalDialogueLines > 0 ? ((stats.successCount / stats.totalDialogueLines) * 100).toFixed(1) : '0.0'}%`,
        estimated_total_duration: script.metadata.estimated_duration,
      },
    };
  }

  /**
   * Save result metadata to file
   */
  private async saveResultMetadata(result: AudioGenerationResult, audioFolderPath: string): Promise<void> {
    const audioListPath = path.join(audioFolderPath, 'audio-files.json');
    await fs.writeFile(audioListPath, JSON.stringify(result, null, 2), 'utf-8');
  }

  /**
   * Print completion summary
   */
  private printCompletionSummary(
    result: AudioGenerationResult,
    audioFolderPath: string,
    totalTime: number
  ): void {
    console.log(`\\nâœ… ë‰´ìŠ¤ìºìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„± ì™„ë£Œ!`);
    console.log(`   ğŸ¬ í”„ë¡œê·¸ë¨: ${result.program_name}`);
    console.log(`   ğŸ“Š ëŒ€í™” ë¼ì¸: ${result.dialogue_lines}ê°œ, ìŒì•… êµ¬ê°„: ${result.music_lines}ê°œ`);
    console.log(`   ğŸ¤ TTS ìƒì„±: ${result.generated_audio_files}ê°œ ì„±ê³µ, ${result.failed_audio_files}ê°œ ì‹¤íŒ¨`);
    console.log(`   ğŸµ ìŒì•… êµ¬ê°„: ${result.skipped_music_files}ê°œ ìŠ¤í‚µ`);
    console.log(`   ğŸ“ˆ TTS ì„±ê³µë¥ : ${result.metadata.success_rate}`);
    console.log(`   â±ï¸ ì˜¤ë””ì˜¤ ìƒì„± ì‹œê°„: ${result.metadata.audio_generation_time_ms.toFixed(1)}ms`);
    console.log(`   ğŸ• ì „ì²´ ì†Œìš” ì‹œê°„: ${totalTime.toFixed(1)}ms`);
    console.log(`   ğŸ“ ì €ì¥ ìœ„ì¹˜: ${audioFolderPath}`);

    if (result.failed_audio_files > 0) {
      console.warn(`\\nâš ï¸ ${result.failed_audio_files}ê°œ ëŒ€ì‚¬ ë¼ì¸ ìƒì„± ì‹¤íŒ¨. Google Cloud TTS API ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.`);
    }
    
    if (result.skipped_music_files > 0) {
      console.log(`\\nğŸ’¡ ${result.skipped_music_files}ê°œ ìŒì•… êµ¬ê°„ì€ ë³„ë„ë¡œ ìŒì•… íŒŒì¼ì„ ì¤€ë¹„í•˜ì—¬ ì¶”ê°€í•´ì£¼ì„¸ìš”:`);
      result.all_segments
        .filter(line => line.type !== 'dialogue')
        .forEach(line => {
          const fileName = `${line.sequence.toString().padStart(3, '0')}-${line.type}.mp3`;
          console.log(`   ğŸµ ${fileName}: ${line.text}`);
        });
    }
  }

  /**
   * Get service status
   */
  public getServiceStatus() {
    return this.ttsService.getServiceStatus();
  }

  /**
   * Reset service state
   */
  public reset(): void {
    this.ttsService.reset();
  }
}